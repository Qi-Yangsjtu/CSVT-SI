# Special Issue on IEEE Transactions on Circuits and Systems for Video Technology

## Volumetric Video Processing and Compression

Volumetric video represents a significant leap forward in capturing, processing, and experiencing 3D content, which can be classified into various forms such as 3D Gaussian splattings (GS), neural radiance fields (NeRF), point clouds, and meshes. Unlike traditional 2D video formats, volumetric video can capture a scene in three dimensions, allowing for fully immersive and interactive experiences. This technology holds promise across a wide range of applications, including virtual reality (VR), augmented reality (AR), gaming, immersive storytelling, and telepresence. However, volumetric video faces significant challenges in several areas that must be addressed to unlock its full capabilities. 1) Acquisition: generating high-quality 3D representations such as GS and NeRF has drawn much interest in recent years. Meanwhile, the raw data captured by 3D sensors such as point clouds are also noisy and incomplete, which poses challenges to subsequent processing. 2) Compression; large data amount of volumetric video content challenges its development and application. Volumetric video usually has a flexible and non-uniform structure, making it difficult to capture sufficient spatial and temporal redundancies. Efficient and time-saving volume video compression methods are urgently needed. 3) Transmission: delivering volumetric video content presents significant challenges due to its massive data size, complex structure, and the need for real-time display. Additionally, user mobility, particularly with six degrees of freedom in VR and AR environments, further complicates interaction with this medium. This underscores the urgent need to design novel transmission systems and algorithms to ensure the high-quality streaming of volumetric videos. 4) Evaluation: effective quality metrics can guide the generation, compression, and transmission algorithms. However, how to qualify the volumetric video, especially emerging data such as NeRF and 3D GS, is still an open problem. Prospective authors are invited to submit original manuscripts on topics including, but not limited to:

1. High-efficiency volumetric video generation
2. Traditional or learning-based volumetric video compression
3. Immersive volumetric video transmission systems and architectures 
4. Traditional or learning-based volumetric video transmission
5. Perceptual-friendly volumetric video quality assessment metrics and loss functions
6. Quality of service & experience and human Factors for immersive volumetric video system

Prospective authors should submit their manuscripts following the IEEE T-CSVT guidelines at https://ieee-cas.org/publication/tcsvt/tcsvt-manuscript-submission-guide.  Authors should submit a PDF version of their complete manuscript to https://ieee.atyponrex.com/submission/dashboard?siteName=TCSVT according to the following schedule:

Submission deadline:  1st June 2025

First Review: 1st July 2025

Revisions due: 1st September 2025

Second Review： 1st October 2025

Final Manuscripts： 1st November 2025

Publication data: 15th November 2025

### Guest Editors:

Yiling Xu： Shanghai Jiao Tong University, China (email: yl.xu@sjtu.edu.cn)

Zhu Li: University of Missouri-Kansas City, USA (email: lizhu@umkc.edu)

Giuseppe Valenzise: University Paris-Saclay, France (email: giuseppe.valenzise@l2s.centralesupelec.fr)

Moncef Gabbouj: Tampere University, Finland.（email: moncef.gabbouj@tuni.fi）

Ronggang Wang: Peking University, China（email: rgwang@pkusz.edu.cn）





